import os, json, datetime, time, requests
import xml.etree.ElementTree as ET
import pandas as pd
import io
import threading
from googleapiclient.discovery import build
from google.oauth2 import service_account
from googleapiclient.http import MediaIoBaseUpload

# ================= 1. ì„¤ì • ë° í™˜ê²½ ë³€ìˆ˜ =================
MY_DIRECT_KEY = os.environ.get('DATA_GO_KR_API_KEY')
AUTH_JSON_STR = os.environ.get('GOOGLE_AUTH_JSON')

HEADER_KOR = ['ì¡°ë‹¬êµ¬ë¶„ëª…', 'ê³„ì•½êµ¬ë¶„ëª…', 'ê³„ì•½ë‚©í’ˆêµ¬ë¶„ëª…', 'ê³„ì•½ë‚©í’ˆìš”êµ¬ì¼ì', 'ê³„ì•½ë‚©í’ˆìš”êµ¬ë²ˆí˜¸', 'ë³€ê²½ì°¨ìˆ˜', 'ìµœì¢…ë³€ê²½ì°¨ìˆ˜ì—¬ë¶€', 'ìˆ˜ìš”ê¸°ê´€ëª…', 'ìˆ˜ìš”ê¸°ê´€êµ¬ë¶„ëª…', 'ìˆ˜ìš”ê¸°ê´€ì§€ì—­ëª…', 'ìˆ˜ìš”ê¸°ê´€ì½”ë“œ', 'ë¬¼í’ˆë¶„ë¥˜ë²ˆí˜¸', 'í’ˆëª…', 'ì„¸ë¶€ë¬¼í’ˆë¶„ë¥˜ë²ˆí˜¸', 'ì„¸ë¶€í’ˆëª…', 'ë¬¼í’ˆì‹ë³„ë²ˆí˜¸', 'ë¬¼í’ˆê·œê²©ëª…', 'ë‹¨ê°€', 'ìˆ˜ëŸ‰', 'ë‹¨ìœ„', 'ê¸ˆì•¡', 'ì—…ì²´ëª…', 'ì—…ì²´ê¸°ì—…êµ¬ë¶„ëª…', 'ê³„ì•½ëª…', 'ìš°ìˆ˜ì œí’ˆì—¬ë¶€', 'ê³µì‚¬ìš©ìì¬ì§ì ‘êµ¬ë§¤ëŒ€ìƒì—¬ë¶€', 'ë‹¤ìˆ˜ê³µê¸‰ìê³„ì•½ì—¬ë¶€', 'ë‹¤ìˆ˜ê³µê¸‰ìê³„ì•½2ë‹¨ê³„ì§„í–‰ì—¬ë¶€', 'ë‹¨ê°€ê³„ì•½ë²ˆí˜¸', 'ë‹¨ê°€ê³„ì•½ë³€ê²½ì°¨ìˆ˜', 'ìµœì´ˆê³„ì•½(ë‚©í’ˆìš”êµ¬)ì¼ì', 'ê³„ì•½ì²´ê²°ë°©ë²•ëª…', 'ì¦ê°ìˆ˜ëŸ‰', 'ì¦ê°ê¸ˆì•¡', 'ë‚©í’ˆì¥ì†Œëª…', 'ë‚©í’ˆê¸°í•œì¼ì', 'ì—…ì²´ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸', 'ì¸ë„ì¡°ê±´ëª…', 'ë¬¼í’ˆìˆœë²ˆ']

CAT_KEYWORDS = {
    'ì˜ìƒê°ì‹œì¥ì¹˜': ['CCTV', 'í†µí•©ê´€ì œ', 'ì˜ìƒê°ì‹œì¥ì¹˜', 'ì˜ìƒì •ë³´ì²˜ë¦¬ê¸°ê¸°'],
    'êµ­ë°©': ['êµ­ë°©', 'ë¶€ëŒ€', 'ì‘ì „', 'ê²½ê³„', 'ë°©ìœ„', 'êµ°ì‚¬', 'ë¬´ì¸í™”', 'ì‚¬ë ¹ë¶€', 'êµ°ëŒ€', 'ì¤‘ìš”ì‹œì„¤', 'ì£¼ë‘”ì§€', 'ê³¼í•™í™”', 'ìœ¡êµ°', 'í•´êµ°', 'ê³µêµ°', 'í•´ë³‘'],
    'ì†”ë£¨ì…˜': ['ë°ì´í„°', 'í”Œë«í¼', 'ì†”ë£¨ì…˜', 'ì£¼ì°¨', 'ì¶œì…', 'GIS'],
    'ìŠ¤ë§ˆíŠ¸ë„ì‹œ': ['ITS', 'ìŠ¤ë§ˆíŠ¸ì‹œí‹°', 'ìŠ¤ë§ˆíŠ¸ë„ì‹œ']
}

keywords = sorted(list(set([
    'ë„¤íŠ¸ì›Œí¬ì‹œìŠ¤í…œì¥ë¹„ìš©ë™','ì˜ìƒê°ì‹œì¥ì¹˜','PAìš©ìŠ¤í”¼ì»¤','ì•ˆë‚´íŒ','ì¹´ë©”ë¼ë¸Œë˜í‚·','ì•¡ì •ëª¨ë‹ˆí„°','ê´‘ì†¡ìˆ˜ì‹ ëª¨ë“ˆ','ì „ì›ê³µê¸‰ì¥ì¹˜','ê´‘ë¶„ë°°í•¨','ì»¨ë²„í„°','ì»´í“¨í„°ì„œë²„','í•˜ë“œë””ìŠ¤í¬ë“œë¼ì´ë¸Œ','ë„¤íŠ¸ì›Œí¬ìŠ¤ìœ„ì¹˜','ê´‘ì í¼ì½”ë“œ','í’€ë°•ìŠ¤','ì„œì§€í¡ìˆ˜ê¸°','ë””ì§€í„¸ë¹„ë””ì˜¤ë ˆì½”ë”',
    'ìŠ¤í”¼ì»¤','ì˜¤ë””ì˜¤ì•°í”„','ë¸Œë˜í‚·','UTPì¼€ì´ë¸”','ì •ë³´í†µì‹ ê³µì‚¬','ì˜ìƒì •ë³´ë””ìŠ¤í”Œë ˆì´ì¥ì¹˜','ì†¡ì‹ ê¸°','ë‚œì—°ì „ë ¥ì¼€ì´ë¸”','1ì¢…ê¸ˆì†ì œê°€ìš”ì „ì„ ê´€','í˜¸ì˜¨ìŠ¤í”¼ì»¤','ëˆ„ì „ì°¨ë‹¨ê¸°','ë°©ì†¡ìˆ˜ì‹ ê¸°','LAPì™¸í”¼ê´‘ì¼€ì´ë¸”','í´ë¦¬ì—í‹¸ë Œì „ì„ ê´€','ë¦¬ëª¨íŠ¸ì•°í”„',
    'ë™ìºë¹„ë‹›ìš©íŒ¨ë„','ë² ì–´ë³¸ì»´í“¨í„°','ë¶„ë°°ê¸°','ê²°ì„ ë³´ë“œìœ ë‹›','ë²¨','ë‚œì—°ì ‘ì§€ìš©ë¹„ë‹ì ˆì—°ì „ì„ ','ê²½ê´‘ë“±','ë°ìŠ¤í¬í†±ì»´í“¨í„°','íŠ¹ìˆ˜ëª©ì ì»´í“¨í„°','ì² ê·¼ì½˜í¬ë¦¬íŠ¸ê³µì‚¬','í† ê³µì‚¬','ì•ˆë‚´ì „ê´‘íŒ','ì ‘ì§€ë´‰','ì¹´ë©”ë¼íšŒì „ëŒ€','ë¬´ì„ ëœì•¡ì„¸ìŠ¤í¬ì¸íŠ¸','ì»´í“¨í„°ë§ì „í™˜ì¥ì¹˜',
    'í¬ì¥ê³µì‚¬','ê³ ì£¼íŒŒë™ì¶•ì¼€ì´ë¸”','ì¹´ë©”ë¼í•˜ìš°ì§•','ì¸í„°í°','ìŠ¤ìœ„ì¹­ëª¨ë“œì „ì›ê³µê¸‰ì¥ì¹˜','ê¸ˆì†ìƒì','ì—´ì„ ê°ì§€ê¸°','íƒœì–‘ì „ì§€ì¡°ì ˆê¸°','ë°€íê³ ì •í˜•ë‚©ì¶•ì „ì§€','IPì „í™”ê¸°','ë””ìŠ¤í¬ì–´ë ˆì´','ê·¸ë˜í”½ìš©ì–´ëŒ‘í„°','ì¸í„°ì½¤ì¥ë¹„','ê¸°ì–µìœ ë‹›','ì»´í“¨í„°ì§€ë¬¸ì¸ì‹ì¥ì¹˜','ëœì ‘ì†ì¹´ë“œ',
    'ì ‘ì§€íŒ','ì œì–´ì¼€ì´ë¸”','ë¹„ë””ì˜¤ë„¤íŠ¸ì›Œí‚¹ì¥ë¹„','ë ˆì´ìŠ¤ì›¨ì´','ì½˜ì†”ìµìŠ¤í…ë”','ì „ìì¹´ë“œ','ë¹„ëŒ€ë©´ë°©ì—­ê°ì§€ì¥ë¹„','ì˜¨ìŠµë„íŠ¸ëœìŠ¤ë¯¸í„°','ë„ë‚œë°©ì§€ê¸°','ìœµë³µí•©ì˜ìƒê°ì‹œì¥ì¹˜','ë©€í‹°ìŠ¤í¬ë¦°ì»´í“¨í„°','ì»´í“¨í„°ì •ë§¥ì¸ì‹ì¥ì¹˜','ì¹´ë©”ë¼ì»¨íŠ¸ë¡¤ëŸ¬','SSDì €ì¥ì¥ì¹˜','ì›ê²©ë‹¨ë§ì¥ì¹˜(RTU)',
    'ìœµë³µí•©ë„¤íŠ¸ì›Œí¬ìŠ¤ìœ„ì¹˜','ìœµë³µí•©ì•¡ì •ëª¨ë‹ˆí„°','ìœµë³µí•©ë°ìŠ¤í¬í†±ì»´í“¨í„°','ìœµë³µí•©ê·¸ë˜í”½ìš©ì–´ëŒ‘í„°','ìœµë³µí•©ë² ì–´ë³¸ì»´í“¨í„°','ìœµë³µí•©ì„œì§€í¡ìˆ˜ê¸°','ë°°ì„ ì¥ì¹˜','ìœµë³µí•©ë°°ì„ ì¥ì¹˜','ìœµë³µí•©ì¹´ë©”ë¼ë¸Œë˜í‚·','ìœµë³µí•©ë„¤íŠ¸ì›Œí¬ì‹œìŠ¤í…œì¥ë¹„ìš©ë™','ìœµë³µí•©UTPì¼€ì´ë¸”','í…Œì´í”„ë°±ì—…ì¥ì¹˜',
    'ìê¸°ì‹í…Œì´í”„','ë ˆì´ë“œì €ì¥ì¥ì¹˜','ê´‘ì†¡ìˆ˜ì‹ ê¸°','450/750V ìœ ì—°ì„±ë‹¨ì‹¬ë¹„ë‹ì ˆì—°ì „ì„ ','ì†”ë‚´ì‹œìŠ¤í…œ','450/750Vìœ ì—°ì„±ë‹¨ì‹¬ë¹„ë‹ì ˆì—°ì „ì„ ','ì¹´ë©”ë¼ë°›ì¹¨ëŒ€','í…”ë ˆë¹„ì „ê±°ì¹˜ëŒ€','ê´‘ìˆ˜ì‹ ê¸°','ë¬´ì„ í†µì‹ ì¥ì¹˜','ë™ì‘ë¶„ì„ê¸°','ì „ë ¥ê³µê¸‰ì¥ì¹˜','450/750V ì¼ë°˜ìš©ìœ ì—°ì„±ë‹¨ì‹¬ë¹„ë‹ì ˆì—°ì „ì„ ','ë¶„ì „í•¨',
    'ë¹„ë””ì˜¤ë¯¹ì„œ','ì ˆì—°ì „ì„ ë°í”¼ë³µì„ ','ë ˆì´ë”','ì ì™¸ì„ ë°©ì‚¬ê¸°', 'ë³´ì•ˆìš©ì¹´ë©”ë¼', 'í†µì‹ ì†Œí”„íŠ¸ì›¨ì–´','ë¶„ì„ë°ê³¼í•™ìš©ì†Œí”„íŠ¸ì›¨ì–´','ì†Œí”„íŠ¸ì›¨ì–´ìœ ì§€ë°ì§€ì›ì„œë¹„ìŠ¤',
    'êµí†µê´€ì œì‹œìŠ¤í…œ', 'ì‚°ì—…ê´€ë¦¬ì†Œí”„íŠ¸ì›¨ì–´', 'ì‹œìŠ¤í…œê´€ë¦¬ì†Œí”„íŠ¸ì›¨ì–´', 'ì ì™¸ì„ ì¹´ë©”ë¼', 'ì£¼ì°¨ê²½ë³´ë“±', 'ì£¼ì°¨ê´€ì œì£¼ë³€ê¸°ê¸°', 'ì£¼ì°¨ê¶ŒíŒë…ê¸°', 'ì£¼ì°¨ì•ˆë‚´íŒ', 'ì£¼ì°¨ìš”ê¸ˆê³„ì‚°ê¸°', 'ì£¼ì°¨ì£¼ì œì–´ì¥ì¹˜', 'ì°¨ëŸ‰ê°ì§€ê¸°', 'ì°¨ëŸ‰ì¸ì‹ê¸°', 'ì°¨ëŸ‰ì°¨ë‹¨ê¸°', 'íŒ¨í‚¤ì§€ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œë°ë„ì…ì„œë¹„ìŠ¤', 'ë¬´ì„ ì¸ì‹ë¦¬ë”ê¸°', 'ë°”ì½”ë“œì‹œìŠ¤í…œ', 'ì¶œì…í†µì œì‹œìŠ¤í…œ', 'ì¹´ë“œì¸ì‡„ê¸°'
])))

NOTICE_API_MAP = {
    'ê³µì‚¬': 'https://apis.data.go.kr/1230000/ad/BidPublicInfoService/getBidPblancListInfoCnstwkPPSSrch',
    'ë¬¼í’ˆ': 'https://apis.data.go.kr/1230000/ad/BidPublicInfoService/getBidPblancListInfoThngPPSSrch',
    'ìš©ì—­': 'https://apis.data.go.kr/1230000/ad/BidPublicInfoService/getBidPblancListInfoServcPPSSrch'
}

# ================= 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ =================
def get_drive_service_for_script():
    info = json.loads(AUTH_JSON_STR)
    creds = service_account.Credentials.from_service_account_info(info, scopes=['https://www.googleapis.com/auth/drive'])
    return build('drive', 'v3', credentials=creds), creds

def get_target_date():
    now = datetime.now(timezone.utc) + timedelta(hours=9)
    return now - datetime.timedelta(days=1)

def classify_text(text):
    for cat, kws in CAT_KEYWORDS.items():
        if any(kw in str(text) for kw in kws): return cat
    return 'ê¸°íƒ€'

def format_html_table(data_list, title):
    html = f"<div style='margin-top:25px;'><h4 style='color:#2c3e50; border-bottom:2px solid #34495e; padding-bottom:8px;'>{title}</h4>"
    if not data_list:
        html += "<p style='color:#888; padding:10px;'>- í•´ë‹¹ ë‚´ì—­ì´ ì—†ìŠµë‹ˆë‹¤.</p></div>"
        return html
    
    html += "<table border='1' style='border-collapse:collapse; width:100%; font-size:13px; line-height:1.8;'>"
    html += "<tr style='background-color:#f8f9fa;'><th>ìˆ˜ìš”ê¸°ê´€</th><th>ëª…ì¹­(ë§í¬)</th><th>ì—…ì²´ëª…</th><th>ê¸ˆì•¡</th></tr>"
    
    for item in data_list:
        corp_name = item.get('corp', '-') 
        bg = "background-color:#FFF9C4;" if "ì´ë…¸ë" in corp_name else ""
        
        amt_val = item.get('amt', '0')
        amt_str = f"{int(amt_val):,}ì›" if str(amt_val).isdigit() else amt_val
        link_name = f"<a href='{item['url']}' target='_blank' style='color:#1a73e8; text-decoration:none;'>{item['nm']}</a>"
        
        html += f"<tr style='{bg}'><td style='padding:8px; text-align:center;'>{item['org']}</td>"
        html += f"<td style='padding:8px;'>{link_name}</td>"
        html += f"<td style='padding:8px; text-align:center;'>{corp_name}</td>"
        html += f"<td style='padding:8px; text-align:right;'>{amt_str}</td></tr>"
    html += "</table></div>"
    return html

def fetch_api_data_from_g2b(kw, d_str):
    url = "https://apis.data.go.kr/1230000/at/ShoppingMallPrdctInfoService/getSpcifyPrdlstPrcureInfoList"
    params = {'numOfRows': '999', 'pageNo': '1', 'ServiceKey': MY_DIRECT_KEY, 'Type_A': 'xml', 'inqryDiv': '1', 'inqryPrdctDiv': '2', 'inqryBgnDate': d_str, 'inqryEndDate': d_str, 'dtilPrdctClsfcNoNm': kw}
    try:
        res = requests.get(url, params=params, timeout=30)
        if res.status_code == 200 and "<item>" in res.text:
            root = ET.fromstring(res.content)
            return [[elem.text if elem.text else '' for elem in elem_item] for elem_item in root.findall('.//item')]
    except: pass
    return []

def fetch_notice_data(category, url, d_str):
    params = {'serviceKey': MY_DIRECT_KEY, 'pageNo': '1', 'numOfRows': '999', 'inqryDiv': '1', 'type': 'json', 'inqryBgnDt': d_str + "0000", 'inqryEndDt': d_str + "2359"}
    try:
        res = requests.get(url, params=params, timeout=45)
        if res.status_code == 200:
            return pd.DataFrame(res.json().get('response', {}).get('body', {}).get('items', []))
    except: pass
    return pd.DataFrame()

# ================= 3. ë©”ì¸ ë¡œì§ =================
def main():
    if not MY_DIRECT_KEY or not AUTH_JSON_STR: return
    target_dt = get_target_date()
    d_str = target_dt.strftime("%Y%m%d")
    display_date = target_dt.strftime("%Yë…„ %mì›” %dì¼")
    weekday_str = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"][target_dt.weekday()]
    drive_service, drive_creds = get_drive_service_for_script()

    # ğŸš€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ í†µí•© ì •ì˜
    keywords_notice_all = [kw for sublist in CAT_KEYWORDS.values() for kw in sublist]

    # --- PART 1: ì¢…í•©ì‡¼í•‘ëª° 3ìë‹¨ê°€ ---
    final_data = []
    for kw in keywords:
        data = fetch_api_data_from_g2b(kw, d_str)
        if data: final_data.extend(data)
    
    school_stats, innodep_today_dict, innodep_total_amt = {}, {}, 0
    if final_data:
        new_df = pd.DataFrame(final_data, columns=HEADER_KOR)
        query = f"name='{target_dt.year}.csv' and trashed=false"
        res = drive_service.files().list(q=query, fields='files(id)').execute()
        items = res.get('files', [])
        f_id = items[0]['id'] if items else None
        if f_id:
            resp = requests.get(f'https://www.googleapis.com/drive/v3/files/{f_id}?alt=media', headers={'Authorization': f'Bearer {drive_creds.token}'})
            old_df = pd.read_csv(io.BytesIO(resp.content), encoding='utf-8-sig', low_memory=False)
            df_to_upload = pd.concat([old_df, new_df], ignore_index=True).drop_duplicates(subset=['ê³„ì•½ë‚©í’ˆìš”êµ¬ì¼ì', 'ìˆ˜ìš”ê¸°ê´€ëª…', 'í’ˆëª…', 'ê¸ˆì•¡'], keep='last')
            media = MediaIoBaseUpload(io.BytesIO(df_to_upload.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')), mimetype='text/csv')
            drive_service.files().update(fileId=f_id, media_body=media).execute()

        for row in final_data:
            org, comp, amt_val, item_nm, cntrct = str(row[7]), str(row[21]), str(row[20]), str(row[14]), str(row[23])
            amt = int(amt_val.replace(',', '').split('.')[0])
            if 'í•™êµ' in org and 'ì§€ëŠ¥í˜•' in cntrct and 'CCTV' in cntrct:
                if org not in school_stats: school_stats[org] = {'total_amt': 0, 'main_vendor': comp}
                school_stats[org]['total_amt'] += amt
            if 'ì´ë…¸ë' in comp:
                innodep_today_dict[org] = innodep_today_dict.get(org, 0) + amt
                innodep_total_amt += amt

    # --- PART 2: ë‚˜ë¼ì¥í„° ì…ì°° ê³µê³  ---
    notice_mail_buckets = {cat: [] for cat in CAT_KEYWORDS}
    all_notice_count = 0

    for cat_api, api_url in NOTICE_API_MAP.items():
        n_df = fetch_notice_data(cat_api, api_url, d_str)
        if not n_df.empty:
            all_notice_count += len(n_df)
            f_name = f"ë‚˜ë¼ì¥í„°_ê³µê³ _{cat_api}.csv"
            res_n = drive_service.files().list(q=f"name='{f_name}' and trashed=false", fields='files(id)').execute()
            if res_n.get('files'):
                fid_n = res_n.get('files')[0]['id']
                resp_n = requests.get(f'https://www.googleapis.com/drive/v3/files/{fid_n}?alt=media', headers={'Authorization': f'Bearer {drive_creds.token}'})
                old_n = pd.read_csv(io.BytesIO(resp_n.content), encoding='utf-8-sig', low_memory=False)
                n_up = pd.concat([old_n, n_df], ignore_index=True).drop_duplicates(subset=['bidNtceNo'], keep='last')
                media_n = MediaIoBaseUpload(io.BytesIO(n_up.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')), mimetype='text/csv')
                drive_service.files().update(fileId=fid_n, media_body=media_n).execute()
            
            pattern = '|'.join(keywords_notice_all)
            filtered = n_df[n_df['bidNtceNm'].str.contains(pattern, na=False, case=False)]
            for _, row in filtered.iterrows():
                cat_found = classify_text(row['bidNtceNm'])
                if cat_found in notice_mail_buckets:
                    notice_mail_buckets[cat_found].append({
                        'org': row.get('dminsttNm', '-'), 'nm': row.get('bidNtceNm', '-'),
                        'amt': row.get('presmptPrce', 'ë³„ë„ê³µê³ '), 'url': row.get('bidNtceDtlUrl', '#')
                    })

    # --- PART 3: ë‚˜ë¼ì¥í„° ê³„ì•½ ë‚´ì—­ ---
    contract_mail_buckets = {cat: [] for cat in CAT_KEYWORDS}
    api_url_servc = 'http://apis.data.go.kr/1230000/ao/CntrctInfoService/getCntrctInfoListServcPPSSrch'
    collected_servc = []
    
    for kw_s in keywords_notice_all:
        p = {'serviceKey': MY_DIRECT_KEY, 'inqryDiv': '1', 'type': 'xml', 'inqryBgnDate': d_str, 'inqryEndDate': d_str, 'cntrctNm': kw_s}
        try:
            r = requests.get(api_url_servc, params=p, timeout=30)
            if r.status_code == 200:
                root = ET.fromstring(r.content)
                for item in root.findall('.//item'):
                    # ğŸš€ [ìˆ˜ì •] í•„ë“œëª…ì„ cntrctDtlInfoUrl ë¡œ ë³€ê²½
                    detail_url = item.findtext('cntrctDtlInfoUrl') 
                    if not detail_url:
                        detail_url = "https://www.g2b.go.kr"
    
                    # ìˆ˜ìš”ê¸°ê´€ëª… ì¶”ì¶œ ë¡œì§ (ë³€ìˆ˜ ì •ì˜ í™•ì¸)
                    raw_demand = item.findtext('dminsttList', '-')
                    clean_demand = raw_demand.replace('[', '').replace(']', '').split('^')[2] if '^' in raw_demand else raw_demand

                    raw_corp = item.findtext('corpList', '-')
                    clean_corp = raw_corp.replace('[', '').replace(']', '').split('^')[3] if '^' in raw_corp else raw_corp
                    
                    collected_servc.append({
                        'org': clean_demand, 
                        'nm': item.findtext('cntrctNm', '-'), 
                        'corp': clean_corp,
                        'amt': item.findtext('totCntrctAmt', '0'), 
                        'url': detail_url
                    })
        except Exception as e:
            print(f"ê³„ì•½ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
    
    unique_servc_list = list({f"{d['org']}_{d['nm']}": d for d in collected_servc}.values())
    for s in unique_servc_list:
        cat_found = classify_text(s['nm'])
        if cat_found in contract_mail_buckets:
            contract_mail_buckets[cat_found].append(s)

    # ğŸš€ êµ­ë°© ê¸°ê´€ í•„í„°ë§
    # ğŸš€ [ìˆ˜ì •] êµ­ë°© ê¸°ê´€ í•„í„°ë§: ë” ìœ ì—°í•˜ê²Œ ë§¤ì¹­ë˜ë„ë¡ ë³´ì™„
    # ğŸš€ [ì¶”ê°€] êµ­ë°© ìš”ì•½ì—ì„œ ì›ì¹˜ ì•ŠëŠ” ê¸°ê´€(í•™êµ, ë¯¼ë°©ìœ„, êµìœ¡ì²­) ì œì™¸ ë¡œì§
    exclude_keywords = ['í•™êµ', 'ë¯¼ë°©ìœ„', 'êµìœ¡ì²­']

    def is_valid_org(org_name):
        # ì œì™¸ í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ ê¸°ê´€ëª…ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ False ë°˜í™˜
        for word in exclude_keywords:
            if word in org_name:
                return False
        return True

    # êµ­ë°© ì„¹ì…˜ì—ì„œ í•´ë‹¹ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°ì´í„° ì œê±°
    notice_mail_buckets['êµ­ë°©'] = [item for item in notice_mail_buckets['êµ­ë°©'] if is_valid_org(item['org'])]
    contract_mail_buckets['êµ­ë°©'] = [item for item in contract_mail_buckets['êµ­ë°©'] if is_valid_org(item['org'])]

    # --- PART 4: ë¦¬í¬íŠ¸ HTML ì¡°ë¦½ ---
    report_html = f"""
    <div style="font-family:'Malgun Gothic'; line-height:2.0; border:1px solid #ddd; padding:20px; border-radius:10px;">
        <h1 style="color:#1a73e8; margin-top:0;">ğŸ“‹ ì¡°ë‹¬ì²­ ë°ì´í„° ìë™ ìˆ˜ì§‘ ë¦¬í¬íŠ¸</h1>
        <b>ğŸ”¹ ìˆ˜ì§‘ë‚ ì§œ :</b> {display_date}({weekday_str}ìš”ì¼)<br>
        <b>ğŸ”¹ ì¢…í•©ì‡¼í•‘ëª° 3ìë‹¨ê°€ ë°ì´í„° :</b> {len(final_data):,}ê±´<br>
        <b>ğŸ”¹ ë‚˜ë¼ì¥í„° ê³µê³  ë°ì´í„° :</b> {all_notice_count:,}ê±´ (í•„í„°ë§ ì „ ì „ì²´)<br>
        <b>ğŸ”¹ ë‚˜ë¼ì¥í„° ê³„ì•½ ë°ì´í„° :</b> {len(unique_servc_list):,}ê±´<br>
        <b>ğŸ”¹ ìƒíƒœ :</b> ì„±ê³µ
        <hr style="border:0.5px solid #eee; margin:20px 0;">
        
        <h1 style='color:#e67e22;'>ğŸ›’ ì¢…í•©ì‡¼í•‘ëª° 3ìë‹¨ê°€ ìš”ì•½</h1>
        <b>â˜… í•™êµ ì§€ëŠ¥í˜• CCTV ë‚©í’ˆ í˜„í™©</b><div style='padding-left:10px; border-left:3px solid #e67e22;'>
    """
    if school_stats:
        for sch, info in school_stats.items(): report_html += f"<p style='margin:5px 0;'>- {sch} / {info['total_amt']:,}ì› / {info['main_vendor']}</p>"
        report_html += f"<b>ğŸ‘‰ í•™êµ ë‚´ì—­ ì´ {len(school_stats)}ê±´ / ì´ì•¡ {sum(s['total_amt'] for s in school_stats.values()):,}ì›</b>"
    else: report_html += "<p> - í•™êµ ë‚´ì—­ 0ê±´</p>"
    
    report_html += "</div><br><b>â˜… ì´ë…¸ë ë‚˜ë¼ì¥í„° ë‚©í’ˆ ì‹¤ì </b><div style='padding-left:10px; border-left:3px solid #e67e22;'>"
    if innodep_today_dict:
        for org, amt in innodep_today_dict.items(): report_html += f"<p style='margin:5px 0;'>- {org} / ì´ì•¡ {amt:,}ì›</p>"
        report_html += f"<b>ğŸ‘‰ ì´ë…¸ë ë‚©í’ˆë‚´ì—­ ì´ {len(innodep_today_dict)}ê±´ / ì´ì•¡ {innodep_total_amt:,}ì›</b>"
    else: report_html += "<p> - ì´ë…¸ë ë‚©í’ˆë‚´ì—­ 0ê±´</p>"
    report_html += "</div>"

    report_html += "<h1 style='margin-top:35px; color:#d32f2f;'>ğŸ“¢ ë‚˜ë¼ì¥í„° ì…ì°° ê³µê³  ìš”ì•½</h1>"
    for i, cat in enumerate(CAT_KEYWORDS.keys(), 1):
        report_html += format_html_table(notice_mail_buckets[cat], f"{i}) {cat} ìš”ì•½")

    report_html += "<h1 style='margin-top:35px; color:#1a73e8;'>ğŸ“ ë‚˜ë¼ì¥í„° ê³„ì•½ ë‚´ì—­ ìš”ì•½</h1>"
    for i, cat in enumerate(CAT_KEYWORDS.keys(), 1):
        report_html += format_html_table(contract_mail_buckets[cat], f"{i}) {cat} ìš”ì•½")
    
    report_html += "</div>"

    if "GITHUB_OUTPUT" in os.environ:
        with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as f:
            f.write(f"collect_date={d_str}\nfull_report<<EOF\n{report_html}\nEOF\n")

if __name__ == "__main__":
    main()
