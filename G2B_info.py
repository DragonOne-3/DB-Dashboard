import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import io
import json
import requests
from google.oauth2 import service_account
import google.auth.transport.requests
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ë””ìì¸ (ë””ìì¸ ì£¼ì„ ì•„ë‹˜, ì‹¤í–‰ ì½”ë“œ) ---
st.set_page_config(page_title="ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰ ì‹œìŠ¤í…œ", layout="wide")

st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    .stTabs [data-baseweb="tab"] {
        background-color: white; border: 1px solid #dee2e6;
        border-radius: 8px 8px 0 0; padding: 10px 15px; font-weight: bold;
    }
    .stTabs [aria-selected="true"] { background-color: #0d6efd !important; color: white !important; }
    .search-panel {
        background: white; padding: 20px; border-radius: 12px;
        border: 1px solid #dee2e6; margin-top: 10px; margin-bottom: 20px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    .stDownloadButton button { width: 100%; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# --- 2. êµ¬ê¸€ ì¸ì¦ ì„œë¹„ìŠ¤ ---
@st.cache_resource
def get_drive_service():
    try:
        # ì‹œí¬ë¦¿ì— ì €ì¥ëœ GOOGLE_AUTH_JSON ì‚¬ìš©
        auth_json_str = st.secrets["GOOGLE_AUTH_JSON"]
        info = json.loads(auth_json_str)
        creds = service_account.Credentials.from_service_account_info(
            info, scopes=['https://www.googleapis.com/auth/drive.readonly', 'https://www.googleapis.com/auth/spreadsheets.readonly']
        )
        return build('drive', 'v3', credentials=creds), creds
    except Exception as e:
        st.error(f"ì¸ì¦ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        st.stop()

drive_service, credentials = get_drive_service()

# --- 3. ë°ì´í„° ì„¤ì • ---
SHEET_FILE_IDS = {
    'ë‚˜ë¼ì¥í„°_ë°œì£¼': '1pGnb6O5Z1ahaHYuQdydyoY1Ayf147IoGmLRdA3WAHi4',
    'ë‚˜ë¼ì¥í„°_ê³„ì•½': '15Hsr_nup4ZteIZ4Jyov8wG2s_rKoZ25muqRE3-sRnaw',
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': '1pzW51Z29SSoQk7al_GvN_tj5smuhOR3J2HWnL_16fcI',
    'êµ°ìˆ˜í’ˆ_ê³„ì•½': '1KPMUz0IKM6AQvqwfAkvW96WNvzbycN56vNlFnDmfRTw',
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': '1opuA_UzNm27U9QkbMay5UsyQqcwfxiEmIHNRdc4MyHM',
    'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': '1aYA18kPrSkpbayzbn16EdKUScVRwr2Nutyid5No5qjk',
    'ì¢…í•©ì‡¼í•‘ëª°': '1N2GjNTpOvtn-5Vbg5zf6Y8kf4xuq0qTr'
}

# íƒ­ë³„ ë‚ ì§œ ì»¬ëŸ¼ ë§¤í•‘
DATE_COL_MAP = {
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': 'ë°œì£¼ì˜ˆì •ì›”', 'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': 'ê°œì°°ì¼ì', 'êµ°ìˆ˜í’ˆ_ê³„ì•½': 'ê³„ì•½ì¼ì',
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': 'ê³µê³ ì¼ì', 'ë‚˜ë¼ì¥í„°_ê³„ì•½': 'â˜…ê°€ê³µ_ê³„ì•½ì¼', 'ì¢…í•©ì‡¼í•‘ëª°': 'ê³„ì•½ë‚©í’ˆìš”êµ¬ì¼ì'
}

# í‘œì¶œ ì»¬ëŸ¼ ì¸ë±ìŠ¤ (ì œê³µí•´ì£¼ì‹  displayIndexMap ê¸°ì¤€)
DISPLAY_COLS = {
    'êµ°ìˆ˜í’ˆ_ê³„ì•½': [7, 5, 3, 1, 12],
    'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': [12, 10, 8, 3],
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': [7, 8, 12, 2, 3], 
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': [0, 17, 15, 22],
    'ë‚˜ë¼ì¥í„°_ë°œì£¼': [9, 13, 20],
    'ë‚˜ë¼ì¥í„°_ê³„ì•½': [0, 3, 4, 5, 6],
    'ì¢…í•©ì‡¼í•‘ëª°': ["ìˆ˜ìš”ê¸°ê´€ëª…", "ê³„ì•½ë‚©í’ˆìš”êµ¬ì¼ì", "ì„¸ë¶€í’ˆëª…", "ê³„ì•½ëª…", "ì—…ì²´ëª…", "ìˆ˜ëŸ‰", "ê¸ˆì•¡"]
}

# --- 4. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data(ttl=3600, show_spinner=False)
def fetch_data(file_id, is_sheet=True):
    auth_req = google.auth.transport.requests.Request()
    credentials.refresh(auth_req)
    if is_sheet:
        url = f"https://docs.google.com/spreadsheets/d/{file_id}/export?format=csv"
        headers = {'Authorization': f'Bearer {credentials.token}'}
        res = requests.get(url, headers=headers)
        return pd.read_csv(io.BytesIO(res.content), low_memory=False)
    else: # ì¢…í•©ì‡¼í•‘ëª° í´ë” ë‚´ CSV ìŠ¤ìº”
        results = drive_service.files().list(q=f"'{file_id}' in parents and trashed = false").execute()
        files = results.get('files', [])
        dfs = []
        for f in files:
            url = f"https://www.googleapis.com/drive/v3/files/{f['id']}?alt=media"
            headers = {'Authorization': f'Bearer {credentials.token}'}
            res = requests.get(url, headers=headers)
            dfs.append(pd.read_csv(io.BytesIO(res.content), low_memory=False))
        return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()

# --- 5. ìƒë‹¨ íƒ€ì´í‹€ ë° ë§í¬ ---
h1, h2 = st.columns([3, 1])
with h1:
    st.title("ğŸ› ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰ ì‹œìŠ¤í…œ")
with h2:
    st.write("")
    st.link_button("ğŸŒ ì§€ìì²´ ìœ ì§€ë³´ìˆ˜ ë°”ë¡œê°€ê¸°", "https://g2b-info.streamlit.app/", use_container_width=True)

# --- 6. íƒ­ êµ¬ì„± ë° ê° íƒ­ë³„ ë¡œì§ ---
tabs = st.tabs(list(SHEET_FILE_IDS.keys()))

for i, tab in enumerate(tabs):
    cat = list(SHEET_FILE_IDS.keys())[i]
    with tab:
        # ê° íƒ­ë³„ ë…ë¦½ ê²€ìƒ‰ íŒ¨ë„
        st.markdown(f"#### ğŸ” {cat} ê²€ìƒ‰ ì¡°ê±´")
        with st.container():
            st.markdown('<div class="search-panel">', unsafe_allow_html=True)
            c1, c2, c3 = st.columns([2.5, 4, 1.5])
            with c1:
                date_range = st.date_input("ì¡°íšŒ ê¸°ê°„", [datetime(2025, 1, 1), datetime.now()], key=f"d_{cat}")
            with c2:
                field = st.selectbox("ê²€ìƒ‰ í•„ë“œ", ["ALL", "ìˆ˜ìš”ê¸°ê´€ëª…", "ì—…ì²´ëª…", "ê³„ì•½ëª…", "ì„¸ë¶€í’ˆëª…"], key=f"f_{cat}")
                k1 = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", key=f"k_{cat}", placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            with c3:
                p_size = st.selectbox("í‘œì‹œ ê°œìˆ˜", [50, 100, 150, 200], key=f"p_{cat}")
                s_btn = st.button("ğŸš€ ê²€ìƒ‰ ì‹¤í–‰", key=f"b_{cat}", type="primary", use_container_width=True)
            st.markdown('</div>', unsafe_allow_html=True)

        if s_btn:
            with st.spinner(f"{cat} ë°ì´í„° ë¶„ì„ ì¤‘..."):
                df = fetch_data(SHEET_FILE_IDS[cat], is_sheet=(cat != 'ì¢…í•©ì‡¼í•‘ëª°'))
                
                if not df.empty:
                    # 1. ë‚ ì§œ í•„í„°ë§ ë¡œì§
                    s_str = date_range[0].strftime('%Y%m%d')
                    e_str = date_range[1].strftime('%Y%m%d') if len(date_range) > 1 else s_str
                    
                    if cat == 'ë‚˜ë¼ì¥í„°_ë°œì£¼':
                        # Eì—´(ë…„ë„: index 4) + Mì—´(ì›”: index 12) ê²°í•©
                        y_col, m_col = df.columns[4], df.columns[12]
                        df['tmp_date'] = df[y_col].astype(str) + df[m_col].astype(str).str.zfill(2) + "01"
                    else:
                        d_col = DATE_COL_MAP.get(cat)
                        if d_col in df.columns:
                            df['tmp_date'] = df[d_col].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8]
                        else:
                            df['tmp_date'] = "00000000"

                    # ê¸°ê°„ ë¹„êµ (ì›” ë‹¨ìœ„ ê²€ìƒ‰ í—ˆìš© ìœ„í•´ s_strì˜ 1ì¼ìë¶€í„° ë¹„êµ)
                    df = df[(df['tmp_date'] >= s_str[:6] + "01") & (df['tmp_date'] <= e_str)]

                    # 2. í‚¤ì›Œë“œ í•„í„°ë§ (í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë§Œ ì ìš©)
                    if k1:
                        if field == "ALL":
                            df = df[df.astype(str).apply(lambda x: x.str.contains(k1, case=False, na=False)).any(axis=1)]
                        elif field in df.columns:
                            df = df[field].astype(str).str.contains(k1, case=False, na=False)

                    if not df.empty:
                        # 3. ë¡œìš°ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                        col_dl, _ = st.columns([1, 4])
                        csv_data = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                        col_dl.download_button("ğŸ“Š ì „ì²´ ë¡œìš°ë°ì´í„°(CSV) ë‹¤ìš´ë¡œë“œ", csv_data, f"{cat}_raw_data.csv", "text/csv")
                        
                        # 4. í‘œì¶œ ì»¬ëŸ¼ ê°€ê³µ
                        s_cols = DISPLAY_COLS.get(cat)
                        f_cols = [df.columns[c] if isinstance(c, int) else c for c in s_cols if (isinstance(c, int) and c < len(df.columns)) or (isinstance(c, str) and c in df.columns)]
                        
                        st.success(f"ì´ {len(df):,}ê±´ì˜ ë°ì´í„°ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        # 5. ë°˜ì‘í˜• í˜ì´ì§• ë°ì´í„°í”„ë ˆì„
                        st.dataframe(df[f_cols].head(p_size), use_container_width=True, height=600)
                    else:
                        st.warning("í•´ë‹¹ ì¡°ê±´ì˜ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.error("ë°ì´í„° ì†ŒìŠ¤ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

st.caption("ğŸ› ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰ | Ver. 2026.01.")
