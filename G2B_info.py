import streamlit as st
import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime, timedelta
import os
import re

API_KEY = os.environ.get('DATA_GO_KR_API_KEY')
API_URL = 'http://apis.data.go.kr/1230000/ao/CntrctInfoService/getCntrctInfoListServcPPSSrch'

st.set_page_config(page_title="ìš©ì—­ ìœ ì§€ë³´ìˆ˜ ë‚´ì—­ ì¡°íšŒ", layout="wide")

def clean_name(raw_text, index):
    if not raw_text or '^' not in raw_text:
        return raw_text
    parts = raw_text.replace('[', '').replace(']', '').split('^')
    return parts[index] if len(parts) > index else raw_text

def fetch_maintenance_data():
    now = datetime.now()
    start_date = datetime(now.year - 1, 1, 1).strftime("%Y%m%d")
    end_date = (now - timedelta(days=1)).strftime("%Y%m%d")
    
    keywords = ['í†µí•©ê´€ì œì„¼í„°', 'CCTV']
    all_rows = []

    status_slot = st.empty()

    for kw in keywords:
        page_no = 1
        while True:
            status_slot.info(f"ğŸ” '{kw}' ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (í˜ì´ì§€: {page_no})")
            params = {
                'serviceKey': API_KEY,
                'pageNo': str(page_no),
                'numOfRows': '999',
                'inqryDiv': '1',
                'type': 'xml',
                'inqryBgnDate': start_date,
                'inqryEndDate': end_date,
                'cntrctNm': kw
            }
            
            try:
                res = requests.get(API_URL, params=params, timeout=30)
                root = ET.fromstring(res.content)
                
                items = root.findall('.//item')
                if not items:
                    break
                
                for item in items:
                    cntrct_nm = item.findtext('cntrctNm', '')
                    
                    # 'ìœ ì§€' ë‹¨ì–´ í¬í•¨ ì—¬ë¶€ í™•ì¸
                    if 'ìœ ì§€' in cntrct_nm.replace(" ", ""):
                        demand = clean_name(item.findtext('dminsttList', ''), 2)
                        corp = clean_name(item.findtext('corpList', ''), 3)
                        
                        cntrct_date_raw = item.findtext('cntrctDate') or item.findtext('cntrctCnclsDate') or ''
                        end_date_raw = item.findtext('ttalScmpltDate', '') # ì´ì™„ìˆ˜ì¼ì
                        amt = int(item.findtext('totCntrctAmt', '0'))
                        
                        # --- ê³„ì•½ë§Œë£Œì¼ ê³„ì‚° ë¡œì§ ---
                        final_end_date = "-"
                        if end_date_raw and cntrct_date_raw:
                            if 'ì¼' in end_date_raw: # '365ì¼' í˜•ì‹
                                try:
                                    days = int(re.sub(r'[^0-9]', '', end_date_raw))
                                    start_dt = datetime.strptime(cntrct_date_raw, "%Y%m%d")
                                    final_end_date = (start_dt + timedelta(days=days)).strftime("%Y-%m-%d")
                                except: final_end_date = end_date_raw
                            else: # '20261231' í˜•ì‹
                                try:
                                    final_end_date = datetime.strptime(end_date_raw, "%Y%m%d").strftime("%Y-%m-%d")
                                except: final_end_date = end_date_raw

                        all_rows.append({
                            'ê³„ì•½ì¼ì': cntrct_date_raw,
                            'ìˆ˜ìš”ê¸°ê´€ëª…': demand,
                            'ê³„ì•½ëª…': cntrct_nm,
                            'ì—…ì²´ëª…': corp,
                            'ê³„ì•½ê¸ˆì•¡': amt,
                            'ê³„ì•½ë§Œë£Œì¼': final_end_date
                        })
                
                total_count_el = root.find('.//totalCount')
                if total_count_el is not None:
                    total_count = int(total_count_el.text)
                    if page_no * 999 >= total_count:
                        break
                else:
                    break
                page_no += 1
                
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                break

    status_slot.empty()
    return pd.DataFrame(all_rows)

st.title("ğŸ›ï¸ ë‚˜ë¼ì¥í„° ìœ ì§€ë³´ìˆ˜ ê³„ì•½ í†µí•© ì¡°íšŒ")

if st.button("ğŸš€ ìµœì‹  ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"):
    with st.spinner("ì „ë…„ë„ë¶€í„° ì–´ì œê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        df = fetch_maintenance_data()
    
    if not df.empty:
        # ì¤‘ë³µ ì œê±° (ìˆ˜ìš”ê¸°ê´€ëª… ê¸°ì¤€ ê°€ì¥ ìµœê·¼ ê³„ì•½ì¼ì ë‚¨ê¹€)
        df = df.sort_values(by='ê³„ì•½ì¼ì', ascending=True)
        df = df.drop_duplicates(subset=['ìˆ˜ìš”ê¸°ê´€ëª…'], keep='last')
        
        # ë‚ ì§œ ë³´ê¸° ì¢‹ê²Œ ë³€ê²½
        df['ê³„ì•½ì¼ì'] = pd.to_datetime(df['ê³„ì•½ì¼ì'], format='%Y%m%d', errors='coerce').dt.strftime('%Y-%m-%d')
        df = df.sort_values(by='ê³„ì•½ì¼ì', ascending=False)

        # ìš”ì•½ í‘œì‹œ
        m1, m2, m3 = st.columns(3)
        m1.metric("ì´ ê³„ì•½ ê¸°ê´€", f"{len(df)}ê³³")
        m2.metric("ì´ ê³„ì•½ ê·œëª¨", f"{df['ê³„ì•½ê¸ˆì•¡'].sum():,}ì›")
        m3.metric("ì¡°íšŒ ë²”ìœ„", "ì „ë…„ë„ 1ì›” ~ ì–´ì œ")

        # ë°ì´í„° í…Œì´ë¸” ì¶œë ¥ (ì»¬ëŸ¼ ìˆœì„œ ì¡°ì •)
        st.dataframe(
            df[['ê³„ì•½ì¼ì', 'ìˆ˜ìš”ê¸°ê´€ëª…', 'ê³„ì•½ëª…', 'ì—…ì²´ëª…', 'ê³„ì•½ê¸ˆì•¡', 'ê³„ì•½ë§Œë£Œì¼']].style.format({'ê³„ì•½ê¸ˆì•¡': '{:,}ì›'}),
            use_container_width=True,
            height=600
        )
        
        # CSV ë‹¤ìš´ë¡œë“œ
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (CSV)", data=csv, file_name=f"ìœ ì§€ë³´ìˆ˜_í˜„í™©_{datetime.now().strftime('%Y%m%d')}.csv", mime="text/csv")
    else:
        st.warning("âš ï¸ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë‚˜ ì‚¬ì´íŠ¸ìƒì˜ ì‹¤ì œ ë“±ë¡ ì—¬ë¶€ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.")
