import streamlit as st
import pandas as pd
from datetime import datetime
import io
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰", layout="wide")

# --- 2. êµ¬ê¸€ ì¸ì¦ ì„œë¹„ìŠ¤ ì„¤ì • (Secrets ì°¸ì¡°) ---
@st.cache_resource
def get_drive_service():
    try:
        # Secretsì—ì„œ ê³„ì¸µí˜•ìœ¼ë¡œ ì €ì¥ëœ ì •ë³´ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
        info = st.secrets.connections.gcs.service_account_info
        creds = service_account.Credentials.from_service_account_info(info)
        return build('drive', 'v3', credentials=creds)
    except Exception as e:
        st.error(f"ì¸ì¦ ì˜¤ë¥˜: Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”. ({e})")
        st.stop()

drive_service = get_drive_service()

# --- 3. ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ---
CSV_FOLDER_ID = '1N2GjNTpOvtn-5Vbg5zf6Y8kf4xuq0qTr' # ì¢…í•©ì‡¼í•‘ëª° CSV í´ë”
SHEET_FILE_IDS = {
    'ë‚˜ë¼ì¥í„°_ë°œì£¼': '1pGnb6O5Z1ahaHYuQdydyoY1Ayf147IoGmLRdA3WAHi4',
    'ë‚˜ë¼ì¥í„°_ê³„ì•½': '15Hsr_nup4ZteIZ4Jyov8wG2s_rKoZ25muqRE3-sRnaw',
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': '1pzW51Z29SSoQk7al_GvN_tj5smuhOR3J2HWnL_16fcI',
    'êµ°ìˆ˜í’ˆ_ê³„ì•½': '1KPMUz0IKM6AQvqwfAkvW96WNvzbycN56vNlFnDmfRTw',
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': '1opuA_UzNm27U9QkbMay5UsyQqcwfxiEmIHNRdc4MyHM',
    'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': '1aYA18kPrSkpbayzbn16EdKUScVRwr2Nutyid5No5qjk'
}
DATE_COL_MAP = {
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': 'ë°œì£¼ì˜ˆì •ì›”', 'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': 'ê°œì°°ì¼ì', 'êµ°ìˆ˜í’ˆ_ê³„ì•½': 'ê³„ì•½ì¼ì',
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': 'ê³µê³ ì¼ì', 'ë‚˜ë¼ì¥í„°_ê³„ì•½': 'â˜…ê°€ê³µ_ê³„ì•½ì¼', 'ì¢…í•©ì‡¼í•‘ëª°': 'ê³„ì•½ë‚©í’ˆìš”êµ¬ì¼ì'
}

# --- 4. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ëŒ€ìš©ëŸ‰ ëŒ€ì‘ ìµœì í™”) ---
@st.cache_data(ttl=3600, show_spinner=False)
def load_csv_file(file_id):
    """ë“œë¼ì´ë¸Œ ë‚´ ì¼ë°˜ CSV íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while not done:
        _, done = downloader.next_chunk()
    fh.seek(0)
    return pd.read_csv(fh, low_memory=False)

@st.cache_data(ttl=3600, show_spinner=False)
def load_large_sheet(file_id):
    """API ìš©ëŸ‰ ì œí•œì„ ìš°íšŒí•˜ì—¬ êµ¬ê¸€ ì‹œíŠ¸ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ì½ì–´ì˜µë‹ˆë‹¤."""
    # export_media ëŒ€ì‹  ì§ì ‘ CSV ë‚´ë³´ë‚´ê¸° URLì„ ì‚¬ìš©í•˜ì—¬ 403 ì˜¤ë¥˜ë¥¼ íšŒí”¼í•©ë‹ˆë‹¤.
    url = f"https://docs.google.com/spreadsheets/d/{file_id}/export?format=csv"
    return pd.read_csv(url, low_memory=False)

# --- 5. ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ í•„í„°")
    category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", list(SHEET_FILE_IDS.keys()) + ["ì¢…í•©ì‡¼í•‘ëª°"], index=6)
    
    col1, col2 = st.columns(2)
    start_date = col1.date_input("ì¡°íšŒ ì‹œì‘ì¼", datetime(2025, 1, 1))
    end_date = col2.date_input("ì¡°íšŒ ì¢…ë£Œì¼", datetime.now())
    
    search_field = st.selectbox("ê²€ìƒ‰ í•„ë“œ", ["ALL", "ìˆ˜ìš”ê¸°ê´€ëª…", "ì—…ì²´ëª…", "ê³„ì•½ëª…", "ì„¸ë¶€í’ˆëª…"])
    k1 = st.text_input("ì²« ë²ˆì§¸ ê²€ìƒ‰ì–´")
    logic = st.selectbox("ê²€ìƒ‰ ë…¼ë¦¬", ["NONE", "AND", "OR"])
    k2 = st.text_input("ë‘ ë²ˆì§¸ ê²€ìƒ‰ì–´") if logic != "NONE" else ""
    
    search_btn = st.button("ë°ì´í„° ê²€ìƒ‰ ì‹¤í–‰", type="primary", use_container_width=True)

# --- 6. ê²€ìƒ‰ ì‹¤í–‰ ë¡œì§ ---
if search_btn:
    with st.spinner("ì„œë²„ì—ì„œ ëŒ€ìš©ëŸ‰ ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        try:
            df = pd.DataFrame()
            s_str = start_date.strftime('%Y%m%d')
            e_str = end_date.strftime('%Y%m%d')

            if category == 'ì¢…í•©ì‡¼í•‘ëª°':
                results = drive_service.files().list(q=f"'{CSV_FOLDER_ID}' in parents and trashed = false").execute()
                files = results.get('files', [])
                relevant_dfs = []
                target_years = [str(y) for y in range(start_date.year, end_date.year + 1)]
                
                for f in files:
                    if any(year in f['name'] for year in target_years):
                        tmp = load_csv_file(f['id'])
                        date_col = tmp.columns[3]
                        tmp['compare_date'] = tmp[date_col].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8]
                        mask = (tmp['compare_date'] >= s_str) & (tmp['compare_date'] <= e_str)
                        relevant_dfs.append(tmp[mask])
                if relevant_dfs:
                    df = pd.concat(relevant_dfs, ignore_index=True)
            else:
                # ëŒ€ìš©ëŸ‰ ì‹œíŠ¸ìš© ìš°íšŒ í•¨ìˆ˜ ì‚¬ìš©
                df = load_large_sheet(SHEET_FILE_IDS[category])
                date_col_name = DATE_COL_MAP.get(category)
                if date_col_name and date_col_name in df.columns:
                    df['compare_date'] = df[date_col_name].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8]
                    df = df[(df['compare_date'] >= s_str) & (df['compare_date'] <= e_str)]

            # í‚¤ì›Œë“œ í•„í„°ë§
            if not df.empty and k1:
                if search_field == "ALL":
                    mask = df.astype(str).apply(lambda x: x.str.contains(k1, case=False, na=False)).any(axis=1)
                else:
                    mask = df[search_field].astype(str).str.contains(k1, case=False, na=False) if search_field in df.columns else [True]*len(df)
                
                if logic == "AND" and k2:
                    mask2 = df.astype(str).apply(lambda x: x.str.contains(k2, case=False, na=False)).any(axis=1) if search_field=="ALL" else df[search_field].astype(str).str.contains(k2, case=False, na=False)
                    df = df[mask & mask2]
                elif logic == "OR" and k2:
                    mask2 = df.astype(str).apply(lambda x: x.str.contains(k2, case=False, na=False)).any(axis=1) if search_field=="ALL" else df[search_field].astype(str).str.contains(k2, case=False, na=False)
                    df = df[mask | mask2]
                else:
                    df = df[mask]

            # ê²°ê³¼ ì¶œë ¥
            if not df.empty:
                st.success(f"ì¡°íšŒ ì™„ë£Œ: {len(df):,}ê±´")
                num_cols = ["ìˆ˜ëŸ‰", "ê¸ˆì•¡", "ë‹¨ê°€"]
                format_dict = {col: "{:,.0f}" for col in num_cols if col in df.columns}
                display_df = df.drop(columns=['compare_date']) if 'compare_date' in df.columns else df
                st.dataframe(display_df.style.format(format_dict), use_container_width=True, height=600)
                
                csv = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button("ğŸ“Š ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, f"{category}.csv", "text/csv")
            else:
                st.warning("ì¡°ê±´ì— ì¼ì¹˜í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

st.caption("ğŸ› ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰ | ëŒ€ìš©ëŸ‰ ë°ì´í„° ìµœì í™” ëª¨ë“œ")
