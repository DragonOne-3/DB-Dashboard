import streamlit as st
import pandas as pd
from datetime import datetime
import io
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

# --- 1. í˜ì´ì§€ ë° ë³´ì•ˆ ì„¤ì • ---
st.set_page_config(page_title="ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰", layout="wide")

# Secretsì—ì„œ ì¸ì¦ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
@st.cache_resource
def get_gdrive_service():
    info = st.secrets["connections"]["gcs"]["service_account_info"]
    creds = service_account.Credentials.from_service_account_info(info)
    return build('drive', 'v3', credentials=creds)

drive_service = get_gdrive_service()

# --- 2. ë°ì´í„° ì†ŒìŠ¤ ì •ë³´ ---
CSV_FOLDER_ID = '1N2GjNTpOvtn-5Vbg5zf6Y8kf4xuq0qTr' 
SHEET_FILE_IDS = {
    'ë‚˜ë¼ì¥í„°_ë°œì£¼': '1pGnb6O5Z1ahaHYuQdydyoY1Ayf147IoGmLRdA3WAHi4',
    'ë‚˜ë¼ì¥í„°_ê³„ì•½': '15Hsr_nup4ZteIZ4Jyov8wG2s_rKoZ25muqRE3-sRnaw',
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': '1pzW51Z29SSoQk7al_GvN_tj5smuhOR3J2HWnL_16fcI',
    'êµ°ìˆ˜í’ˆ_ê³„ì•½': '1KPMUz0IKM6AQvqwfAkvW96WNvzbycN56vNlFnDmfRTw',
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': '1opuA_UzNm27U9QkbMay5UsyQqcwfxiEmIHNRdc4MyHM',
    'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': '1aYA18kPrSkpbayzbn16EdKUScVRwr2Nutyid5No5qjk'
}
DATE_COL_MAP = {
    'êµ°ìˆ˜í’ˆ_ë°œì£¼': 'ë°œì£¼ì˜ˆì •ì›”', 'êµ°ìˆ˜í’ˆ_ìˆ˜ì˜': 'ê°œì°°ì¼ì', 'êµ°ìˆ˜í’ˆ_ê³„ì•½': 'ê³„ì•½ì¼ì',
    'êµ°ìˆ˜í’ˆ_ê³µê³ ': 'ê³µê³ ì¼ì', 'ë‚˜ë¼ì¥í„°_ê³„ì•½': 'â˜…ê°€ê³µ_ê³„ì•½ì¼', 'ì¢…í•©ì‡¼í•‘ëª°': 'ê³„ì•½ë‚©í’ˆìš”êµ¬ì¼ì'
}

# --- 3. íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data(ttl=3600, show_spinner=False)
def download_csv(file_id):
    request = drive_service.files().get_media(fileId=file_id)
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while done is False:
        status, done = downloader.next_chunk()
    fh.seek(0)
    return pd.read_csv(fh, low_memory=False)

@st.cache_data(ttl=3600, show_spinner=False)
def download_sheet_as_csv(file_id):
    # êµ¬ê¸€ ì‹œíŠ¸ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°
    request = drive_service.files().export_media(fileId=file_id, mimeType='text/csv')
    fh = io.BytesIO()
    downloader = MediaIoBaseDownload(fh, request)
    done = False
    while done is False:
        status, done = downloader.next_chunk()
    fh.seek(0)
    return pd.read_csv(fh, low_memory=False)

# --- 4. ì‚¬ì´ë“œë°” UI ---
with st.sidebar:
    st.header("ğŸ” ê²€ìƒ‰ í•„í„°")
    category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", list(SHEET_FILE_IDS.keys()) + ["ì¢…í•©ì‡¼í•‘ëª°"], index=6)
    col1, col2 = st.columns(2)
    start_date = col1.date_input("ì¡°íšŒ ì‹œì‘ì¼", datetime(2025, 1, 1))
    end_date = col2.date_input("ì¡°íšŒ ì¢…ë£Œì¼", datetime.now())
    search_field = st.selectbox("ê²€ìƒ‰ í•„ë“œ", ["ALL", "ìˆ˜ìš”ê¸°ê´€ëª…", "ì—…ì²´ëª…", "ê³„ì•½ëª…", "ì„¸ë¶€í’ˆëª…"])
    k1 = st.text_input("ì²« ë²ˆì§¸ ê²€ìƒ‰ì–´")
    logic = st.selectbox("ê²€ìƒ‰ ë…¼ë¦¬", ["NONE", "AND", "OR"])
    k2 = st.text_input("ë‘ ë²ˆì§¸ ê²€ìƒ‰ì–´") if logic != "NONE" else ""
    search_btn = st.button("ë°ì´í„° ê²€ìƒ‰ ì‹¤í–‰", type="primary", width='stretch')

# --- 5. ê²€ìƒ‰ ë¡œì§ ---
if search_btn:
    with st.spinner("êµ¬ê¸€ ë“œë¼ì´ë¸Œì—ì„œ ì§ì ‘ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤..."):
        try:
            df = pd.DataFrame()
            s_str = start_date.strftime('%Y%m%d')
            e_str = end_date.strftime('%Y%m%d')

            if category == 'ì¢…í•©ì‡¼í•‘ëª°':
                # í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
                results = drive_service.files().list(
                    q=f"'{CSV_FOLDER_ID}' in parents and trashed = false",
                    fields="files(id, name)"
                ).execute()
                files = results.get('files', [])
                
                relevant_dfs = []
                target_years = [str(y) for y in range(start_date.year, end_date.year + 1)]
                
                for f in files:
                    if any(year in f['name'] for year in target_years):
                        tmp = download_csv(f['id'])
                        date_col = tmp.columns[3]
                        tmp['compare_date'] = tmp[date_col].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8]
                        mask = (tmp['compare_date'] >= s_str) & (tmp['compare_date'] <= e_str)
                        relevant_dfs.append(tmp[mask])
                if relevant_dfs: df = pd.concat(relevant_dfs, ignore_index=True)
            else:
                df = download_sheet_as_csv(SHEET_FILE_IDS[category])
                date_col_name = DATE_COL_MAP.get(category)
                if date_col_name and date_col_name in df.columns:
                    df['compare_date'] = df[date_col_name].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8]
                    df = df[(df['compare_date'] >= s_str) & (df['compare_date'] <= e_str)]

            # --- í‚¤ì›Œë“œ í•„í„°ë§ ---
            if not df.empty and k1:
                if search_field == "ALL":
                    mask = df.astype(str).apply(lambda x: x.str.contains(k1, case=False, na=False)).any(axis=1)
                else:
                    mask = df[search_field].astype(str).str.contains(k1, case=False, na=False)
                
                if logic == "AND" and k2:
                    mask2 = df.astype(str).apply(lambda x: x.str.contains(k2, case=False, na=False)).any(axis=1) if search_field=="ALL" else df[search_field].astype(str).str.contains(k2, case=False, na=False)
                    df = df[mask & mask2]
                elif logic == "OR" and k2:
                    mask2 = df.astype(str).apply(lambda x: x.str.contains(k2, case=False, na=False)).any(axis=1) if search_field=="ALL" else df[search_field].astype(str).str.contains(k2, case=False, na=False)
                    df = df[mask | mask2]
                else:
                    df = df[mask]

            # --- ê²°ê³¼ ì¶œë ¥ ---
            if not df.empty:
                st.success(f"ì¡°íšŒ ì™„ë£Œ: {len(df):,}ê±´")
                num_cols = ["ìˆ˜ëŸ‰", "ê¸ˆì•¡", "ë‹¨ê°€"]
                format_dict = {col: "{:,.0f}" for col in num_cols if col in df.columns}
                display_df = df.drop(columns=['compare_date']) if 'compare_date' in df.columns else df
                st.dataframe(display_df.style.format(format_dict), width='stretch', height=600)
                csv = df.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')
                st.download_button("ğŸ“Š ì—‘ì…€(CSV) ë‹¤ìš´ë¡œë“œ", csv, f"{category}_ê²€ìƒ‰ê²°ê³¼.csv", "text/csv")
            else:
                st.warning("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

st.caption("ğŸ› ê³µê³µì¡°ë‹¬ DATA í†µí•©ê²€ìƒ‰ | Google API ì§ì ‘ í˜¸ì¶œ ëª¨ë“œ")
