import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime, timedelta
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import json
import time
from urllib.parse import unquote

# --- ì„¤ì • ---
# API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ë©°, ì¸ì½”ë”©/ë””ì½”ë”© ì´ìŠˆ ë°©ì§€ë¥¼ ìœ„í•´ unquote ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤.
API_KEY = unquote(os.environ.get('DATA_GO_KR_API_KEY', ''))
API_URL = 'http://apis.data.go.kr/1230000/ao/CntrctInfoService/getCntrctInfoListServcPPSSrch'

# ì œì™¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ê²€ìƒ‰ ê²°ê³¼ ì¤‘ ì•„ë˜ ë‹¨ì–´ê°€ í¬í•¨ëœ ê³„ì•½ëª…ì€ ì œì™¸)
EXCLUDE_KEYWORDS = [
    'ê°ë¦¬', 'ë°ì´í„°ë² ì´ìŠ¤', 'êµìœ¡', 'ISP', 'êµ¬ì¡°ë¬¼', 'ê´€ê´‘', 'ê°€ëª…', 'ìµëª…', 'ê²€í† ', 'ì˜ë£Œ', 'ê·€ë†', 'ê·€ì´Œ',
    'ì‹¤ì‹œ', 'ì„¤ê³„', 'ë°”ì´ì˜¤', 'ì½˜í…ì¸ ', 'ê±°ë˜', 'íƒ„ì†Œ', 'ë†ìˆ˜ì‚°ë¬¼', 'ë„ë§¤', 'ì»¨ì„¤íŒ…', 'ê°€ì´ë“œë¼ì¸', 'êµ¿ì¦ˆ', 'íê¸°ë¬¼', 'ì¸ì‚¬', 'ìœ¡ì•„', 'ìˆ˜ì‚°ë¬¼', 'ëª©ì¬', 'ì£¼ì†Œ',
    'í•˜ë“œì›¨ì–´', '3ì°¨ì›', '3D', 'ìœ ì‚°', 'ë¬¸í™”', 'ëŒ€í–‰'
]

def get_gs_client():
    auth_json = os.environ.get('GOOGLE_AUTH_JSON')
    creds_dict = json.loads(auth_json)
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    return gspread.authorize(creds)

def main():
    # 1. ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (2025ë…„ 1ì›” 1ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€)
    start_dt = datetime(2025, 1, 1)
    end_dt = datetime.now()
    
    # ìˆ˜ì§‘í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    keywords = list(set([
        'CCTV', 'í†µí•©ê´€ì œ', 'ì£¼ì°¨ê´€ë¦¬', 'ì˜ìƒê°ì‹œì¥ì¹˜', 'ì˜ìƒì •ë³´ì²˜ë¦¬ê¸°ê¸°', 'êµ­ë°©', 'ë¶€ëŒ€', 'ì‘ì „', 'ê²½ê³„', 'ë°©ìœ„',
        'ë°ì´í„°','í”Œë«í¼','ì†”ë£¨ì…˜','êµ°ì‚¬', 'ë¬´ì¸í™”', 'ì‚¬ë ¹ë¶€', 'êµ°ëŒ€','ìŠ¤ë§ˆíŠ¸ì‹œí‹°','ìŠ¤ë§ˆíŠ¸ë„ì‹œ','ITS','GIS'
    ]))
    
    all_fetched_rows = []

    print(f"ğŸš€ {start_dt.strftime('%Y%m%d')} ~ {end_dt.strftime('%Y%m%d')} ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # 2. ë‚ ì§œë¥¼ 30ì¼ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ìˆ˜ì§‘
    current_dt = start_dt
    while current_dt <= end_dt:
        chunk_start = current_dt.strftime("%Y%m%d")
        chunk_end_dt = current_dt + timedelta(days=29)
        if chunk_end_dt > end_dt: chunk_end_dt = end_dt
        chunk_end = chunk_end_dt.strftime("%Y%m%d")
        
        for kw in keywords:
            params = {
                'serviceKey': API_KEY, 
                'pageNo': '1', 
                'numOfRows': '999',
                'inqryDiv': '1', 
                'type': 'xml', 
                'inqryBgnDate': chunk_start, 
                'inqryEndDate': chunk_end, 
                'cntrctNm': kw
            }
            
            try:
                res = requests.get(API_URL, params=params, timeout=60)
                
                if res.status_code == 200:
                    if res.text.strip().startswith('<?xml'):
                        root = ET.fromstring(res.content)
                        items = root.findall('.//item')
                        
                        total_found = len(items)  # APIì—ì„œ ê²€ìƒ‰ëœ ì „ì²´ ê±´ìˆ˜
                        saved_count = 0           # í•„í„° í†µê³¼ í›„ ì €ì¥ë  ê±´ìˆ˜
                        filtered_count = 0        # ì œì™¸ í‚¤ì›Œë“œë¡œ ê±¸ëŸ¬ì§„ ê±´ìˆ˜
                        
                        for item in items:
                            raw = {child.tag: child.text for child in item}
                            cntrct_nm = raw.get('cntrctNm', '')
                            
                            # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
                            if any(ex_kw in cntrct_nm for ex_kw in EXCLUDE_KEYWORDS):
                                filtered_count += 1
                                continue
                            
                            # ìˆ˜ìš”ê¸°ê´€ ë° ì—…ì²´ëª… ì •ì œ
                            raw_demand = raw.get('dminsttList', '')
                            demand_parts = raw_demand.replace('[', '').replace(']', '').split('^')
                            clean_demand = demand_parts[2] if len(demand_parts) > 2 else raw_demand
                            
                            raw_corp = raw.get('corpList', '')
                            corp_parts = raw_corp.replace('[', '').replace(']', '').split('^')
                            clean_corp = corp_parts[3] if len(corp_parts) > 3 else raw_corp

                            processed = {
                                'â˜…ê°€ê³µ_ê³„ì•½ì¼': raw.get('cntrctDate', ''),
                                'â˜…ê°€ê³µ_ì°©ìˆ˜ì¼': raw.get('stDate', '-'),
                                'â˜…ê°€ê³µ_ë§Œë£Œì¼': raw.get('ttalScmpltDate') or raw.get('thtmScmpltDate') or '-',
                                'â˜…ê°€ê³µ_ìˆ˜ìš”ê¸°ê´€': clean_demand,
                                'â˜…ê°€ê³µ_ê³„ì•½ëª…': cntrct_nm,
                                'â˜…ê°€ê³µ_ì—…ì²´ëª…': clean_corp,
                                'â˜…ê°€ê³µ_ê³„ì•½ê¸ˆì•¡': int(raw.get('totCntrctAmt', 0)) if raw.get('totCntrctAmt') else 0
                            }
                            processed.update(raw)
                            all_fetched_rows.append(processed)
                            saved_count += 1
                        
                        if total_found > 0:
                            print(f"  > [{chunk_start}~{chunk_end}] '{kw}': ì´ {total_found}ê±´ ë°œê²¬ (ì €ì¥: {saved_count}ê±´, í•„í„°ì œì™¸: {filtered_count}ê±´)")
                    else:
                        print(f"  âš ï¸ {kw} ì‘ë‹µ ì˜¤ë¥˜ (XML ì•„ë‹˜): {res.text[:100]}...")
                else:
                    print(f"  âŒ {kw} HTTP ì—ëŸ¬: {res.status_code}")
            
            except Exception as e:
                print(f"  âŒ {kw} í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            time.sleep(0.5) # íŠ¸ë˜í”½ ì°¨ë‹¨ ë°©ì§€
            
        current_dt = chunk_end_dt + timedelta(days=1)

    # 3. ë°ì´í„° ì¤‘ë³µ ì œê±° ë° êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥
    if all_fetched_rows:
        df = pd.DataFrame(all_fetched_rows)
        # ê³„ì•½ë²ˆí˜¸(cntrctNo) ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        if 'cntrctNo' in df.columns:
            df = df.drop_duplicates(subset=['cntrctNo'])
        else:
            df = df.drop_duplicates()

        try:
            sh = get_gs_client().open("ë‚˜ë¼ì¥í„°_ìš©ì—­ê³„ì•½ë‚´ì—­")
            ws = sh.get_worksheet(0)
            
            # ì²« ë²ˆì§¸ í–‰ì´ ë¹„ì–´ìˆìœ¼ë©´ ì œëª© í–‰ ì¶”ê°€
            if not ws.row_values(1):
                ws.insert_row(df.columns.tolist(), 1)
                print("âœ… ì œëª©í–‰ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            # êµ¬ê¸€ ì‹œíŠ¸ ë°ì´í„° ì „ì†¡ (ë¶„í•  ì „ì†¡ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´)
            values = df.fillna('').values.tolist()
            for i in range(0, len(values), 3000):
                ws.append_rows(values[i:i+3000], value_input_option='RAW')
            
            print(f"âœ… ìµœì¢… {len(df)}ê±´ ë°ì´í„° ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì‹œíŠ¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        print(f"â„¹ï¸ {start_dt.strftime('%Y-%m-%d')} ì´í›„ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ 0ê±´ì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
