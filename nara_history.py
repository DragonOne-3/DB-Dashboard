import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime, timedelta
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import json
import time
from urllib.parse import unquote # ì¶”ê°€

# --- ì„¤ì • ---
# API í‚¤ëŠ” ì¼ë°˜ê³µê³µë°ì´í„° í¬í„¸ì—ì„œ ë°›ì€ 'ì¸ì½”ë”©' í‚¤ë¥¼ ê·¸ëŒ€ë¡œ ë„£ê±°ë‚˜, 'ë””ì½”ë”©' í‚¤ë¥¼ ë„£ìœ¼ì…”ë„ ë©ë‹ˆë‹¤.
# ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ unquote ì²˜ë¦¬ë¥¼ í•œ ë²ˆ ê±°ì¹©ë‹ˆë‹¤.
API_KEY = unquote(os.environ.get('DATA_GO_KR_API_KEY', ''))
API_URL = 'http://apis.data.go.kr/1230000/ao/CntrctInfoService/getCntrctInfoListServcPPSSrch'

# ì œì™¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
EXCLUDE_KEYWORDS = [
    'ê°ë¦¬', 'ë°ì´í„°ë² ì´ìŠ¤', 'êµìœ¡', 'ISP', 'êµ¬ì¡°ë¬¼', 'ê´€ê´‘', 'ê°€ëª…', 'ìµëª…', 'ê²€í† ', 'ì˜ë£Œ', 'ê·€ë†', 'ê·€ì´Œ',
    'ì‹¤ì‹œ', 'ì„¤ê³„', 'ë°”ì´ì˜¤', 'ì½˜í…ì¸ ', 'ê±°ë˜', 'íƒ„ì†Œ', 'ë†ìˆ˜ì‚°ë¬¼', 'ë„ë§¤', 'ì»¨ì„¤íŒ…', 'ê°€ì´ë“œë¼ì¸', 'êµ¿ì¦ˆ', 'íê¸°ë¬¼', 'ì¸ì‚¬', 'ìœ¡ì•„', 'ìˆ˜ì‚°ë¬¼', 'ëª©ì¬', 'ì£¼ì†Œ',
    'í•˜ë“œì›¨ì–´', '3ì°¨ì›', '3D', 'ìœ ì‚°', 'ë¬¸í™”', 'ëŒ€í–‰'
]

def get_gs_client():
    auth_json = os.environ.get('GOOGLE_AUTH_JSON')
    creds_dict = json.loads(auth_json)
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    return gspread.authorize(creds)

def main():
    # 1. ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (ë„ˆë¬´ ê¸¸ë©´ ì„œë²„ì—ì„œ ì°¨ë‹¨í•˜ë¯€ë¡œ í™•ì¸ìš©ìœ¼ë¡œ ì§§ê²Œ í…ŒìŠ¤íŠ¸ í›„ ëŠ˜ë¦¬ì„¸ìš”)
    start_dt = datetime(2025, 1, 1)
    end_dt = datetime.now()
    
    # ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±°
    keywords = list(set(['CCTV', 'í†µí•©ê´€ì œ', 'ì£¼ì°¨ê´€ë¦¬', 'ì˜ìƒê°ì‹œì¥ì¹˜', 'ì˜ìƒì •ë³´ì²˜ë¦¬ê¸°ê¸°', 'êµ­ë°©', 'ë¶€ëŒ€', 'ì‘ì „', 'ê²½ê³„', 'ë°©ìœ„','ë°ì´í„°','í”Œë«í¼','ì†”ë£¨ì…˜','êµ°ì‚¬', 'ë¬´ì¸í™”', 'ì‚¬ë ¹ë¶€', 'êµ°ëŒ€','ìŠ¤ë§ˆíŠ¸ì‹œí‹°','ìŠ¤ë§ˆíŠ¸ë„ì‹œ','ITS','GIS']))
    all_fetched_rows = []

    print(f"ğŸš€ {start_dt.strftime('%Y%m%d')} ~ {end_dt.strftime('%Y%m%d')} ìˆ˜ì§‘ ì‹œì‘")

    current_dt = start_dt
    while current_dt <= end_dt:
        chunk_start = current_dt.strftime("%Y%m%d")
        chunk_end_dt = current_dt + timedelta(days=29)
        if chunk_end_dt > end_dt: chunk_end_dt = end_dt
        chunk_end = chunk_end_dt.strftime("%Y%m%d")
        
        for kw in keywords:
            params = {
                'serviceKey': API_KEY, 
                'pageNo': '1', 
                'numOfRows': '999',
                'inqryDiv': '1', 
                'type': 'xml', 
                'inqryBgnDate': chunk_start, 
                'inqryEndDate': chunk_end, 
                'cntrctNm': kw
            }
            
            try:
                # paramsë¥¼ í†µí•´ ë³´ë‚´ë©´ requestsê°€ ìë™ ì¸ì½”ë”©í•©ë‹ˆë‹¤.
                res = requests.get(API_URL, params=params, timeout=60)
                
                if res.status_code == 200:
                    if res.text.strip().startswith('<?xml'):
                        root = ET.fromstring(res.content)
                        items = root.findall('.//item')
                        
                        count = 0
                        for item in items:
                            raw = {child.tag: child.text for child in item}
                            cntrct_nm = raw.get('cntrctNm', '')
                            
                            if any(ex_kw in cntrct_nm for ex_kw in EXCLUDE_KEYWORDS):
                                continue
                            
                            # ë°ì´í„° ì •ì œ (ê¸°ì¡´ ë¡œì§)
                            raw_demand = raw.get('dminsttList', '')
                            demand_parts = raw_demand.replace('[', '').replace(']', '').split('^')
                            clean_demand = demand_parts[2] if len(demand_parts) > 2 else raw_demand
                            
                            raw_corp = raw.get('corpList', '')
                            corp_parts = raw_corp.replace('[', '').replace(']', '').split('^')
                            clean_corp = corp_parts[3] if len(corp_parts) > 3 else raw_corp

                            processed = {
                                'â˜…ê°€ê³µ_ê³„ì•½ì¼': raw.get('cntrctDate', ''),
                                'â˜…ê°€ê³µ_ì°©ìˆ˜ì¼': raw.get('stDate', '-'),
                                'â˜…ê°€ê³µ_ë§Œë£Œì¼': raw.get('ttalScmpltDate') or raw.get('thtmScmpltDate') or '-',
                                'â˜…ê°€ê³µ_ìˆ˜ìš”ê¸°ê´€': clean_demand,
                                'â˜…ê°€ê³µ_ê³„ì•½ëª…': cntrct_nm,
                                'â˜…ê°€ê³µ_ì—…ì²´ëª…': clean_corp,
                                'â˜…ê°€ê³µ_ê³„ì•½ê¸ˆì•¡': int(raw.get('totCntrctAmt', 0)) if raw.get('totCntrctAmt') else 0
                            }
                            processed.update(raw)
                            all_fetched_rows.append(processed)
                            count += 1
                        
                        print(f"  > [{chunk_start}~{chunk_end}] '{kw}': {count}ê±´ ì €ì¥ì™„ë£Œ")
                    else:
                        # ì—ëŸ¬ ì›ì¸ ë¶„ì„ì„ ìœ„í•´ ì‹¤ì œ ì‘ë‹µ ì•ë¶€ë¶„ ì¶œë ¥
                        print(f"  âš ï¸ {kw} ì‘ë‹µ ì˜¤ë¥˜: {res.text[:100]}...")
                else:
                    print(f"  âŒ {kw} HTTP ì—ëŸ¬: {res.status_code}")
            
            except Exception as e:
                print(f"  âŒ {kw} í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•´ ê°„ê²© ìœ ì§€ (íŠ¸ë˜í”½ ì—ëŸ¬ ë°œìƒ ì‹œ 1ì´ˆ ì´ìƒìœ¼ë¡œ ëŠ˜ë¦¬ì„¸ìš”)
            time.sleep(0.5) 
            
        current_dt = chunk_end_dt + timedelta(days=1)

    # 3. ë°ì´í„° ì¤‘ë³µ ì œê±° ë° ì‹œíŠ¸ ì €ì¥ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
    # ... (ì´í•˜ ìƒëµ) ...
