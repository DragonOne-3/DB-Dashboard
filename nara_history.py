import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime, timedelta
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import json
import time
from urllib.parse import unquote

# --- ì„¤ì • ---
API_KEY = unquote(os.environ.get('DATA_GO_KR_API_KEY', ''))
API_URL = 'http://apis.data.go.kr/1230000/ao/CntrctInfoService/getCntrctInfoListServcPPSSrch'

# ì œì™¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
EXCLUDE_KEYWORDS = [
    'ê°ë¦¬', 'ë°ì´í„°ë² ì´ìŠ¤', 'êµìœ¡', 'ISP', 'êµ¬ì¡°ë¬¼', 'ê´€ê´‘', 'ê°€ëª…', 'ìµëª…', 'ê²€í† ', 'ì˜ë£Œ', 'ê·€ë†', 'ê·€ì´Œ',
    'ì‹¤ì‹œ', 'ì„¤ê³„', 'ë°”ì´ì˜¤', 'ì½˜í…ì¸ ', 'ê±°ë˜', 'íƒ„ì†Œ', 'ë†ìˆ˜ì‚°ë¬¼', 'ë„ë§¤', 'ì»¨ì„¤íŒ…', 'ê°€ì´ë“œë¼ì¸', 'êµ¿ì¦ˆ', 'íê¸°ë¬¼', 'ì¸ì‚¬', 'ìœ¡ì•„', 'ìˆ˜ì‚°ë¬¼', 'ëª©ì¬', 'ì£¼ì†Œ',
    'í•˜ë“œì›¨ì–´', '3ì°¨ì›', '3D', 'ìœ ì‚°', 'ë¬¸í™”', 'ëŒ€í–‰'
]

def get_gs_client():
    auth_json = os.environ.get('GOOGLE_AUTH_JSON')
    creds_dict = json.loads(auth_json)
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    return gspread.authorize(creds)

def main():
    # 1. ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì • (2024ë…„ 1ì›” 1ì¼ ~ í˜„ì¬)
    start_dt = datetime(2024, 1, 1)
    end_dt = datetime.now()
    
    keywords = list(set([
        'CCTV', 'í†µí•©ê´€ì œ', 'ì£¼ì°¨ê´€ë¦¬', 'ì˜ìƒê°ì‹œì¥ì¹˜', 'ì˜ìƒì •ë³´ì²˜ë¦¬ê¸°ê¸°', 'êµ­ë°©', 'ë¶€ëŒ€', 'ì‘ì „', 'ê²½ê³„', 'ë°©ìœ„',
        'ë°ì´í„°','í”Œë«í¼','ì†”ë£¨ì…˜','êµ°ì‚¬', 'ë¬´ì¸í™”', 'ì‚¬ë ¹ë¶€', 'êµ°ëŒ€','ìŠ¤ë§ˆíŠ¸ì‹œí‹°','ìŠ¤ë§ˆíŠ¸ë„ì‹œ','ITS','GIS'
    ]))
    
    all_fetched_rows = []

    print(f"ğŸš€ {start_dt.strftime('%Y-%m-%d')} ~ {end_dt.strftime('%Y-%m-%d')} ê³¼ê±° ë°ì´í„° ì „ì²´ ìˆ˜ì§‘ ì‹œì‘")

    # 2. ë‚ ì§œë¥¼ 30ì¼ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ìˆ˜ì§‘ (API ê³¼ë¶€í•˜ ë° ëˆ„ë½ ë°©ì§€)
    current_dt = start_dt
    while current_dt <= end_dt:
        chunk_start = current_dt.strftime("%Y%m%d")
        chunk_end_dt = current_dt + timedelta(days=29)
        if chunk_end_dt > end_dt: chunk_end_dt = end_dt
        chunk_end = chunk_end_dt.strftime("%Y%m%d")
        
        print(f"ğŸ“… êµ¬ê°„ ìˆ˜ì§‘ ì¤‘: {chunk_start} ~ {chunk_end}")
        
        for kw in keywords:
            params = {
                'serviceKey': API_KEY, 
                'pageNo': '1', 
                'numOfRows': '999',
                'inqryDiv': '1', 
                'type': 'xml', 
                'inqryBgnDate': chunk_start, 
                'inqryEndDate': chunk_end, 
                'cntrctNm': kw
            }
            
            try:
                res = requests.get(API_URL, params=params, timeout=60)
                
                if res.status_code == 200:
                    content = res.text.strip()
                    # ì˜ ì‘ë™í–ˆë˜ "XML ì„ ì–¸ë¬¸ ë¬´ì‹œ" ë¡œì§ ì ìš©
                    if content.startswith('<?xml') or content.startswith('<response'):
                        root = ET.fromstring(res.content)
                        
                        result_code = root.find('.//resultCode')
                        if result_code is not None and result_code.text == '00':
                            items = root.findall('.//item')
                            total_found = len(items)
                            saved_count = 0
                            
                            for item in items:
                                raw = {child.tag: child.text for child in item}
                                cntrct_nm = raw.get('cntrctNm', '')
                                
                                # ì œì™¸ í‚¤ì›Œë“œ ì²´í¬
                                if any(ex_kw in cntrct_nm for ex_kw in EXCLUDE_KEYWORDS):
                                    continue
                                
                                # ë°ì´í„° ì •ì œ
                                raw_demand = raw.get('dminsttList', '') or ''
                                demand_parts = raw_demand.replace('[', '').replace(']', '').split('^')
                                clean_demand = demand_parts[2] if len(demand_parts) > 2 else raw_demand
                                
                                raw_corp = raw.get('corpList', '') or ''
                                corp_parts = raw_corp.replace('[', '').replace(']', '').split('^')
                                clean_corp = corp_parts[3] if len(corp_parts) > 3 else raw_corp

                                processed = {
                                    'â˜…ê°€ê³µ_ê³„ì•½ì¼': raw.get('cntrctDate', ''),
                                    'â˜…ê°€ê³µ_ì°©ìˆ˜ì¼': raw.get('stDate', '-'),
                                    'â˜…ê°€ê³µ_ë§Œë£Œì¼': raw.get('ttalScmpltDate') or raw.get('thtmScmpltDate') or '-',
                                    'â˜…ê°€ê³µ_ìˆ˜ìš”ê¸°ê´€': clean_demand,
                                    'â˜…ê°€ê³µ_ê³„ì•½ëª…': cntrct_nm,
                                    'â˜…ê°€ê³µ_ì—…ì²´ëª…': clean_corp,
                                    'â˜…ê°€ê³µ_ê³„ì•½ê¸ˆì•¡': int(raw.get('totCntrctAmt', 0)) if raw.get('totCntrctAmt') else 0
                                }
                                processed.update(raw)
                                all_fetched_rows.append(processed)
                                saved_count += 1
                            
                            if total_found > 0:
                                print(f"   > '{kw}': {total_found}ê±´ ë°œê²¬ (ì €ì¥: {saved_count}ê±´)")
                        else:
                            print(f"   âŒ {kw} API ì—ëŸ¬ ì½”ë“œ: {result_code.text if result_code is not None else 'None'}")
                    else:
                        print(f"   âš ï¸ {kw} ì‘ë‹µ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ (ì²« 50ì): {content[:50]}")
                else:
                    print(f"   âŒ {kw} HTTP ì—ëŸ¬: {res.status_code}")
            
            except Exception as e:
                print(f"   âŒ {kw} í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            
            time.sleep(0.3) # ê³¼ê±° ë°ì´í„°ëŠ” ìš”ì²­ì´ ë§ìœ¼ë¯€ë¡œ ì•½ê°„ì˜ ëŒ€ê¸°ì‹œê°„ ìœ ì§€
            
        current_dt = chunk_end_dt + timedelta(days=1)

    # 3. ì¤‘ë³µ ì œê±° ë° êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥
    if all_fetched_rows:
        df = pd.DataFrame(all_fetched_rows)
        if 'cntrctNo' in df.columns:
            df = df.drop_duplicates(subset=['cntrctNo'])
        else:
            df = df.drop_duplicates()

        try:
            sh = get_gs_client().open("ë‚˜ë¼ì¥í„°_ìš©ì—­ê³„ì•½ë‚´ì—­")
            ws = sh.get_worksheet(0)
            
            # ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì œëª© í–‰ ì‚½ì…
            if not ws.row_values(1):
                ws.insert_row(df.columns.tolist(), 1)
            
            # ê³¼ê±° ë°ì´í„°ëŠ” ì–‘ì´ ë§ìœ¼ë¯€ë¡œ 2000ì¤„ì”© ëŠì–´ì„œ ì „ì†¡ (ì•ˆì •ì„±)
            values = df.fillna('').values.tolist()
            for i in range(0, len(values), 2000):
                ws.append_rows(values[i:i+2000], value_input_option='RAW')
                print(f"ğŸ“¤ {i+len(values[i:i+2000])} / {len(values)} ì¤„ ì—…ë¡œë“œ ì¤‘...")
            
            print(f"âœ… ê³¼ê±° ë°ì´í„° ì´ {len(df)}ê±´ ëˆ„ì  ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ì‹œíŠ¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
    else:
        print("â„¹ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
