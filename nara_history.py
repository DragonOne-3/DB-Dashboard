import requests
import xml.etree.ElementTree as ET
import pandas as pd
from datetime import datetime, timedelta
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import os
import json
import time
import re
import traceback
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- ì„¤ì • ---
API_KEY = os.environ.get('DATA_GO_KR_API_KEY')
API_URL = 'http://apis.data.go.kr/1230000/ao/CntrctInfoService/getCntrctInfoListServcPPSSrch'
MAX_WORKERS = 5 # ë™ì‹œì— ì‹¤í–‰í•  ì‘ì—… ìˆ˜ (í‚¤ì›Œë“œ ê°œìˆ˜ì™€ ë§ì¶¤)

def get_gspread_client():
    auth_json = os.environ.get('GOOGLE_AUTH_JSON')
    creds_dict = json.loads(auth_json)
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
    return gspread.authorize(creds)

def clean_name(raw_text, index):
    if not raw_text or '^' not in raw_text: return raw_text
    parts = raw_text.replace('[', '').replace(']', '').split('^')
    return parts[index] if len(parts) > index else raw_text

def format_date(date_str):
    if not date_str or len(date_str) < 8: return "-"
    try: return datetime.strptime(date_str[:8], "%Y%m%d").strftime("%Y-%m-%d")
    except: return date_str

def fetch_single_keyword(kw, start_date, end_date):
    """íŠ¹ì • í‚¤ì›Œë“œ í•œ ê°œì— ëŒ€í•´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í•¨ìˆ˜ (ë³‘ë ¬ ì‹¤í–‰ìš©)"""
    keyword_rows = []
    page_no = 1
    while True:
        params = {
            'serviceKey': API_KEY, 'pageNo': str(page_no), 'numOfRows': '999',
            'inqryDiv': '1', 'type': 'xml', 'inqryBgnDate': start_date, 'inqryEndDate': end_date, 'cntrctNm': kw
        }
        try:
            res = requests.get(API_URL, params=params, timeout=60)
            if not res.text.strip().endswith('</response>'): break
            root = ET.fromstring(res.content)
            items = root.findall('.//item')
            if not items: break
            
            for item in items:
                raw_dict = {child.tag: child.text for child in item}
                raw_c_date = raw_dict.get('cntrctDate') or raw_dict.get('cntrctCnclsDate') or ''
                raw_s_date = raw_dict.get('stDate', '') 
                raw_e_date = raw_dict.get('ttalScmpltDate') or raw_dict.get('thtmScmpltDate') or ''
                
                fmt_e_date = "-"
                if raw_e_date:
                    if 'ì¼' in raw_e_date and raw_c_date:
                        try:
                            days_val = int(re.sub(r'[^0-9]', '', raw_e_date))
                            fmt_e_date = (datetime.strptime(raw_c_date[:8], "%Y%m%d") + timedelta(days=days_val)).strftime("%Y-%m-%d")
                        except: fmt_e_date = raw_e_date
                    else: fmt_e_date = format_date(raw_e_date)

                processed_dict = {
                    'â˜…ê°€ê³µ_ê³„ì•½ì¼': format_date(raw_c_date),
                    'â˜…ê°€ê³µ_ì°©ìˆ˜ì¼': format_date(raw_s_date),
                    'â˜…ê°€ê³µ_ë§Œë£Œì¼': fmt_e_date,
                    'â˜…ê°€ê³µ_ìˆ˜ìš”ê¸°ê´€': clean_name(raw_dict.get('dminsttList', ''), 2),
                    'â˜…ê°€ê³µ_ê³„ì•½ëª…': raw_dict.get('cntrctNm', ''),
                    'â˜…ê°€ê³µ_ì—…ì²´ëª…': clean_name(raw_dict.get('corpList', ''), 3),
                    'â˜…ê°€ê³µ_ê³„ì•½ê¸ˆì•¡': int(raw_dict.get('totCntrctAmt', '0'))
                }
                processed_dict.update(raw_dict)
                keyword_rows.append(processed_dict)
            
            total_count = int(root.find('.//totalCount').text)
            if page_no * 999 >= total_count: break
            page_no += 1
            time.sleep(0.3)
        except: break
    return keyword_rows

def main():
    try:
        client = get_gspread_client()
        sh = client.open("ë‚˜ë¼ì¥í„°_ìš©ì—­ê³„ì•½ë‚´ì—­")
        ws = sh.get_worksheet(0)
        
        keywords = ['CCTV', 'í†µí•©ê´€ì œ', 'ì£¼ì°¨ê´€ë¦¬', 'ì˜ìƒê°ì‹œì¥ì¹˜', 'ì˜ìƒì •ë³´ì²˜ë¦¬ê¸°ê¸°']
        start_date = datetime(2024, 1, 1)
        end_date = datetime.now() - timedelta(days=1)
        
        # ì œëª©ì¤„ ì²´í¬
        if not ws.acell('A1').value:
            sample = fetch_single_keyword(keywords[0], "20240101", "20240101")
            if sample: ws.update('A1', [list(sample[0].keys())])

        current_date = start_date
        while current_date <= end_date:
            # ê¸°ê°„ ë‹¨ìœ„ (ë³‘ë ¬ ì²˜ë¦¬ ì‹œì—ëŠ” 14ì¼ ì •ë„ë¡œ ì¡°ê¸ˆ ë” ë„“ê²Œ ì¡ì•„ë„ ì•ˆì „í•©ë‹ˆë‹¤)
            chunk_start = current_date.strftime("%Y%m%d")
            chunk_end_dt = current_date + timedelta(days=13)
            if chunk_end_dt > end_date: chunk_end_dt = end_date
            chunk_end = chunk_end_dt.strftime("%Y%m%d")
            
            print(f"ğŸš€ ë³‘ë ¬ ìˆ˜ì§‘ ì‹œì‘: {chunk_start} ~ {chunk_end}")
            
            all_period_data = []
            # --- ë³‘ë ¬ ì‹¤í–‰ êµ¬ê°„ ---
            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                futures = {executor.submit(fetch_single_keyword, kw, chunk_start, chunk_end): kw for kw in keywords}
                for future in as_completed(futures):
                    kw_result = future.result()
                    all_period_data.extend(kw_result)
            # --------------------

            if all_period_data:
                df = pd.DataFrame(all_period_data).fillna('')
                ws.append_rows(df.values.tolist(), value_input_option='RAW')
                print(f"   âœ… {len(df)}ê±´ ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ (êµ¬ê°„ í•©ê³„)")
                time.sleep(2) # êµ¬ê¸€ API ì•ˆì •í™”
            
            current_date = chunk_end_dt + timedelta(days=1)

        print("ğŸŠ ë³‘ë ¬ ìˆ˜ì§‘ ë° ì €ì¥ì´ ëª¨ë‘ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        traceback.print_exc()

if __name__ == "__main__":
    main()
